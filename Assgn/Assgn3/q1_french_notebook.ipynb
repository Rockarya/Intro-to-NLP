{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# GPU ON KRKE RUN ALL -> google colab mein kr dena run isko\nimport re\nimport random\nimport nltk\nimport math\nnltk.download('punkt')\nimport numpy as np\nimport pandas as pd\n# for progress bars\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport joblib\nimport spacy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"SDU58hz-RaiK","outputId":"c60dab1b-ee8c-4c5c-8947-534326aa6363","execution":{"iopub.status.busy":"2022-04-12T12:46:48.106478Z","iopub.execute_input":"2022-04-12T12:46:48.107905Z","iopub.status.idle":"2022-04-12T12:46:48.127266Z","shell.execute_reply.started":"2022-04-12T12:46:48.107859Z","shell.execute_reply":"2022-04-12T12:46:48.126315Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# HYPER PARAMETERS\n\n# sequence length for the sequence-target pair\nseq_len = 5\n\n# batch size\nbatch_size = 16\n\n# number of epochs\nepochs = 5\n\n# learning rate\nlr = 0.001\n\n# clip\nclip = 1\n\n# threshold -> for handling unknown words. If the frequency comes out to be less than threshold, then we will replace the token with unk\nthreshold = 2","metadata":{"id":"50zUTR4FRaiW","execution":{"iopub.status.busy":"2022-04-12T12:46:48.129180Z","iopub.execute_input":"2022-04-12T12:46:48.129549Z","iopub.status.idle":"2022-04-12T12:46:48.140615Z","shell.execute_reply.started":"2022-04-12T12:46:48.129506Z","shell.execute_reply":"2022-04-12T12:46:48.139325Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# read file\nfile_name = '../input/dataset/intro-to-nlp-assign3/news-crawl-corpus/train.news'\nf = open(file_name)\ntext = f.read()\nf.close()","metadata":{"id":"v0QW3wC-Raie","execution":{"iopub.status.busy":"2022-04-12T12:46:48.141985Z","iopub.execute_input":"2022-04-12T12:46:48.142570Z","iopub.status.idle":"2022-04-12T12:46:48.228523Z","shell.execute_reply.started":"2022-04-12T12:46:48.142522Z","shell.execute_reply":"2022-04-12T12:46:48.227868Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!python3 -m spacy download fr_core_news_sm\nspacy_fr = spacy.load('fr_core_news_sm')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:46:48.230912Z","iopub.execute_input":"2022-04-12T12:46:48.231539Z","iopub.status.idle":"2022-04-12T12:47:22.283946Z","shell.execute_reply.started":"2022-04-12T12:46:48.231485Z","shell.execute_reply":"2022-04-12T12:47:22.283075Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"text = text.lower()\nlst = nltk.tokenize.sent_tokenize(text)\n\nsentences = []\nfor sent in lst:\n    sentences.append([tok.text for tok in spacy_fr.tokenizer(sent)])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:47:22.285185Z","iopub.execute_input":"2022-04-12T12:47:22.285408Z","iopub.status.idle":"2022-04-12T12:47:27.599886Z","shell.execute_reply.started":"2022-04-12T12:47:22.285383Z","shell.execute_reply":"2022-04-12T12:47:27.598997Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# frequency count\nfreq = {}\nfor sent in sentences:\n    for word in sent:\n        if freq.get(word) == None:\n            freq[word] = 1\n        else:\n            freq[word] += 1\n\npure_sentences = []\nfor sent in sentences:\n    pure = ''\n    for word in sent:\n        if freq[word] >= threshold:\n            pure += word\n        else:\n            pure += 'unk'\n\n        pure += ' '\n    pure_sentences.append(pure)","metadata":{"id":"VR9UBvRYRaij","execution":{"iopub.status.busy":"2022-04-12T12:48:43.000692Z","iopub.execute_input":"2022-04-12T12:48:43.000979Z","iopub.status.idle":"2022-04-12T12:48:43.416580Z","shell.execute_reply.started":"2022-04-12T12:48:43.000950Z","shell.execute_reply":"2022-04-12T12:48:43.415513Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# creating sequence-target pair and also storing all the distinct words\nseq = []\ndist_words = set()\nfor string in pure_sentences:\n    # we will take seq_len+1 and then divide this into input_sequence and output_sequence     \n    sent = string.split()\n    if len(sent) >= seq_len:\n        for i in range(seq_len,len(sent)):\n            seq.append(\" \".join(sent[i-seq_len:i+1]))\n        \n    for word in sent:\n        dist_words.add(word)\n        \n# vocabulary size\nvocab_size = len(dist_words)\n    \ninp = []\nout = []\nfor sq in seq:\n    inp.append(\" \".join(sq.split()[:-1]))  # from first word to last second word \n    out.append(\" \".join(sq.split()[1:]))   # from second word to last word\n\n    \n# creating word_to_index and index_to_word dictionary\nword_to_index = {}\nindex_to_word = {}\nfor cnt,word in enumerate(dist_words):\n    word_to_index[word] = cnt\n    index_to_word[cnt] = word","metadata":{"id":"n56ty9NBRaip","execution":{"iopub.status.busy":"2022-04-12T12:49:32.110144Z","iopub.execute_input":"2022-04-12T12:49:32.110859Z","iopub.status.idle":"2022-04-12T12:49:33.054046Z","shell.execute_reply.started":"2022-04-12T12:49:32.110822Z","shell.execute_reply":"2022-04-12T12:49:33.052929Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"joblib.dump(word_to_index,'word_to_index_q1.pkl')\njoblib.dump(index_to_word,'index_to_word_q1.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:49:33.484561Z","iopub.execute_input":"2022-04-12T12:49:33.484853Z","iopub.status.idle":"2022-04-12T12:49:33.790537Z","shell.execute_reply.started":"2022-04-12T12:49:33.484824Z","shell.execute_reply":"2022-04-12T12:49:33.789685Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(vocab_size, len(inp))\nprint(seq[0]+'\\n'+inp[0]+'\\n'+out[0])","metadata":{"id":"DsHKSaKWRaiv","outputId":"659aca06-a6b3-4e26-8208-05547de34ae5","execution":{"iopub.status.busy":"2022-04-12T12:49:37.910534Z","iopub.execute_input":"2022-04-12T12:49:37.910810Z","iopub.status.idle":"2022-04-12T12:49:37.916316Z","shell.execute_reply.started":"2022-04-12T12:49:37.910779Z","shell.execute_reply":"2022-04-12T12:49:37.915481Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# As we have got the index for each word, now convert inp and out to their corresponding word's indices\ninp_index = []\nout_index = []\nfor i in range(len(inp)):\n    inp_index.append([word_to_index[word] for word in inp[i].split()])\n    out_index.append([word_to_index[word] for word in out[i].split()])\n    \ninp_index = np.array(inp_index)\nout_index = np.array(out_index)","metadata":{"id":"lo7kcTW3Raiz","execution":{"iopub.status.busy":"2022-04-12T12:49:43.632166Z","iopub.execute_input":"2022-04-12T12:49:43.632457Z","iopub.status.idle":"2022-04-12T12:49:46.588227Z","shell.execute_reply.started":"2022-04-12T12:49:43.632413Z","shell.execute_reply":"2022-04-12T12:49:46.587288Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# creating batches\ndef make_batch(inp, out, batch_size):\n    ind = 0\n    for n in range(batch_size, len(inp), batch_size):\n        x = inp[ind:n,:]\n        y = out[ind:n,:]\n        ind = n\n        # yield is used to return from a function without destroying the states of its local variable \n        # and when the function is called, the execution starts from the last yield statement.         \n        yield x, y","metadata":{"id":"D-2ZS0LHRai2","execution":{"iopub.status.busy":"2022-04-12T12:49:51.096529Z","iopub.execute_input":"2022-04-12T12:49:51.096813Z","iopub.status.idle":"2022-04-12T12:49:51.102810Z","shell.execute_reply.started":"2022-04-12T12:49:51.096786Z","shell.execute_reply":"2022-04-12T12:49:51.101661Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Declaring out Model\nclass WordLSTM(nn.Module):\n    \n    def __init__(self, n_hidden=256, n_layers=4, drop_prob=0.3, lr=0.001):\n        super().__init__()\n\n        self.drop_prob = drop_prob\n        self.n_layers = n_layers\n        self.n_hidden = n_hidden\n        self.lr = lr\n        \n        self.emb_layer = nn.Embedding(vocab_size, 200)\n\n        ## define the LSTM\n        self.lstm = nn.LSTM(200, n_hidden, n_layers, \n                            dropout=drop_prob, batch_first=True)\n        \n        ## define a dropout layer\n        self.dropout = nn.Dropout(drop_prob)\n        \n        ## define the fully-connected layer\n        self.fc = nn.Linear(n_hidden, vocab_size)      \n    \n    def forward(self, x, hidden):\n        ''' Forward pass through the network. \n            These inputs are x, and the hidden/cell state `hidden`. '''\n\n        ## pass input through embedding layer\n        embedded = self.emb_layer(x)     \n        \n        ## Get the outputs and the new hidden state from the lstm\n        lstm_output, hidden = self.lstm(embedded, hidden)\n        \n        ## pass through a dropout layer\n        out = self.dropout(lstm_output)\n        \n        #out = out.contiguous().view(-1, self.n_hidden) \n        out = out.reshape(-1, self.n_hidden) \n\n        ## put \"out\" through the fully-connected layer\n        out = self.fc(out)\n\n        # return the final output and the hidden state\n        return out, hidden\n    \n    \n    def init_hidden(self, batch_size):\n        ''' initializes hidden state '''\n        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n        # initialized to zero, for hidden state and cell state of LSTM\n        weight = next(self.parameters()).data\n\n        # if GPU is available\n        if (torch.cuda.is_available()):\n            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n        \n        # if GPU is not available\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n        \n        return hidden","metadata":{"id":"jqo2eBaoRai6","execution":{"iopub.status.busy":"2022-04-12T12:49:51.986018Z","iopub.execute_input":"2022-04-12T12:49:51.986293Z","iopub.status.idle":"2022-04-12T12:49:51.997474Z","shell.execute_reply.started":"2022-04-12T12:49:51.986267Z","shell.execute_reply":"2022-04-12T12:49:51.996588Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# instantiate the model\nnet = WordLSTM()\n# push the model to GPU (avoid it if you are not using the GPU)\nnet.cuda()\nprint(net)","metadata":{"id":"EyBJhgEXRajA","outputId":"f03f7f5a-fe01-4102-f808-e4eb1f50553d","execution":{"iopub.status.busy":"2022-04-12T12:49:53.625272Z","iopub.execute_input":"2022-04-12T12:49:53.626092Z","iopub.status.idle":"2022-04-12T12:49:53.869165Z","shell.execute_reply.started":"2022-04-12T12:49:53.626046Z","shell.execute_reply":"2022-04-12T12:49:53.867955Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train(net, epochs, batch_size, lr, clip):\n    opt = torch.optim.Adam(net.parameters(), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n    net.cuda()\n    \n    net.train()\n    for e in range(epochs):\n        # initialize hidden state\n        h = net.init_hidden(batch_size)\n        for x, y in make_batch(inp_index, out_index, batch_size):\n            inputs, targets = torch.from_numpy(x).cuda(), torch.from_numpy(y).cuda()\n            # detach hidden states\n            h = tuple([each.data for each in h])\n            net.zero_grad()\n            output, h = net(inputs, h)\n            loss = criterion(output, targets.view(-1))\n            loss.backward()\n            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n            nn.utils.clip_grad_norm_(net.parameters(), clip)\n            opt.step() \n        \n        print('Epoch {} done!'.format(e+1))","metadata":{"id":"neD0LytORajE","execution":{"iopub.status.busy":"2022-04-12T12:45:23.896972Z","iopub.status.idle":"2022-04-12T12:45:23.89778Z","shell.execute_reply.started":"2022-04-12T12:45:23.897444Z","shell.execute_reply":"2022-04-12T12:45:23.897475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model & save it\ntrain(net, epochs, batch_size, lr, clip)\ntorch.save(net.state_dict(),'q1_french.pt')","metadata":{"id":"a3STHj0fRajJ","execution":{"iopub.status.busy":"2022-04-12T12:45:23.899456Z","iopub.status.idle":"2022-04-12T12:45:23.900195Z","shell.execute_reply.started":"2022-04-12T12:45:23.89991Z","shell.execute_reply":"2022-04-12T12:45:23.899941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perplexity(sentence):\n    # push to GPU\n    net.cuda()\n    net.eval()\n\n    # batch size is 1\n    h = net.init_hidden(1)\n    \n    sentence = sentence.lower()\n    sentence = re.sub(\"[^a-z']\", \" \", sentence)\n    indices = []\n    for token in sentence.split():\n        if word_to_index.get(token) == None:\n            indices.append(word_to_index['unk'])\n        else:\n            indices.append(word_to_index[token])\n\n    length = len(indices)\n    lst = np.array([indices])\n\n    # tensor inputs\n    inputs = torch.from_numpy(lst).cuda()\n\n    # get the output of the model\n    out, h = net(inputs, h)\n\n    # get the token probabilities\n    p = F.softmax(out, dim=1).data\n    p = p.cpu().numpy()\n\n    logarithm_sum = 0.0\n    for i,ind in enumerate(indices):\n        logarithm_sum += (math.log(p[i][ind]))/length\n        \n    # we already took division by length, so no need to divide here by length     \n    return math.exp(-logarithm_sum)\n    ","metadata":{"id":"HCeflk34RajM","execution":{"iopub.status.busy":"2022-04-12T12:45:23.901829Z","iopub.status.idle":"2022-04-12T12:45:23.902621Z","shell.execute_reply.started":"2022-04-12T12:45:23.902278Z","shell.execute_reply":"2022-04-12T12:45:23.902338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = perplexity('the results are acceptable.')\nprint(p)","metadata":{"id":"SDj3_8a59Kls","execution":{"iopub.status.busy":"2022-04-12T12:45:23.904226Z","iopub.status.idle":"2022-04-12T12:45:23.905103Z","shell.execute_reply.started":"2022-04-12T12:45:23.904733Z","shell.execute_reply":"2022-04-12T12:45:23.904764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}