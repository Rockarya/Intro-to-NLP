{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# The below notebook was ran on kaggle\nimport torch\nimport torch.nn as nn\nimport random\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport string\n# for progress bars\nfrom tqdm import tqdm\nimport json\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import PCA\nfrom nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:13:30.089113Z","iopub.execute_input":"2022-04-07T13:13:30.089367Z","iopub.status.idle":"2022-04-07T13:13:32.962752Z","shell.execute_reply.started":"2022-04-07T13:13:30.089336Z","shell.execute_reply":"2022-04-07T13:13:32.961918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cpu\"\nif torch.cuda.is_available():\n    print('using device: cuda')\n    device = \"cuda\"\nelse:\n    print('using device: cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:13:32.964593Z","iopub.execute_input":"2022-04-07T13:13:32.965187Z","iopub.status.idle":"2022-04-07T13:13:33.019855Z","shell.execute_reply.started":"2022-04-07T13:13:32.965146Z","shell.execute_reply":"2022-04-07T13:13:33.01905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading data\nsentences = []\nwith open('../input/electronics-5json/Electronics_5.json') as f:\n    for jsonObj in f:\n        sent = json.loads(jsonObj)\n        sentences.append(sent['reviewText'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:13:34.451908Z","iopub.execute_input":"2022-04-07T13:13:34.45255Z","iopub.status.idle":"2022-04-07T13:14:00.167367Z","shell.execute_reply.started":"2022-04-07T13:13:34.452513Z","shell.execute_reply":"2022-04-07T13:14:00.166596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# storing frequency of each token. Will remove the tokens whose frequency is less than a partcular threshold like 5\nfrequency = {}\nnum_of_training_sentences = 5000\nlst = []\n\nstop_words = set(stopwords.words('english'))\n\n# filtering the top num_of_training sentences\nfor i in range(num_of_training_sentences):\n    sent = sentences[i].lower()\n    pure = ''\n    for ch in sent:\n        if ch not in string.punctuation:\n            pure += ch\n        else:\n            pure += ' '\n    lst.append(pure)\n    \npure_sentences = []\nfor i in range(num_of_training_sentences):\n    sent = lst[i]\n    pure = ''\n    for w in sent.split():\n        if w.isalpha() and w not in stop_words:\n            pure += w\n            pure += ' '\n            \n            if frequency.get(w) == None:\n                frequency[w] = 1\n            else:\n                frequency[w] += 1\n                \n    pure_sentences.append(pure)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:14:00.170731Z","iopub.execute_input":"2022-04-07T13:14:00.170937Z","iopub.status.idle":"2022-04-07T13:14:01.436772Z","shell.execute_reply.started":"2022-04-07T13:14:00.170912Z","shell.execute_reply":"2022-04-07T13:14:01.436002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set good value of threshold\nthreshold = 5\nwords = []\nindex_dict = {}\nindex_dict['PAD'] = 0\ncnt = 1\nfor w in frequency.keys():\n    if frequency[w] >= threshold:\n        words.append(w)\n        index_dict[w] = cnt\n        cnt += 1\n        \nvocab_size = len(words) + 1 #we have already added 'PAD' at index 0\nthresh_sentences = []\nfor sent in pure_sentences:\n    thresh = []\n    for w in sent.split():\n        if index_dict.get(w) != None:\n            thresh.append(w)\n    thresh_sentences.append(thresh)\n    \n\n# generating context-target pairs\nwindow_size = 2\nnegative_sampling = 5 #number of negative samples which needs to be added\n\ninp_contexts = []\nfor lst in thresh_sentences:\n    sent_len = len(lst)\n    for ind in range(sent_len):\n        start = max(0,ind-window_size)\n        end = min(sent_len,ind+window_size+1) \n        \n        context_indices = [] # -> we are storing in this format:- a,b,c,d,  word,  k-negative samples. where a,b,c,d are context words.\n        for i in range(start,end):\n            if i != ind:\n                context_indices.append(index_dict[lst[i]])\n                \n        # index of the word         \n        context_indices.append(index_dict[lst[ind]])\n                \n        # assigning k random words which are not context of given word         \n        for i in range(negative_sampling):\n            while 1:\n                # generating in range of 0 to vocab_size -1                 \n                k = random.randint(0,vocab_size-1)\n                if k not in context_indices:\n                    break\n            context_indices.append(k)\n            \n                \n        #padding  \n        context_len = 1 + 2*window_size + negative_sampling \n        if len(context_indices) < context_len:\n            context_indices = [0]*(context_len - len(context_indices)) + list(context_indices)\n            \n        inp_contexts.append(context_indices)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:14:01.440096Z","iopub.execute_input":"2022-04-07T13:14:01.440305Z","iopub.status.idle":"2022-04-07T13:14:05.964074Z","shell.execute_reply.started":"2022-04-07T13:14:01.440279Z","shell.execute_reply":"2022-04-07T13:14:05.963284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dims = 300\nclass CBOW(torch.nn.Module):\n    def __init__(self, vocab_size, embedding_dim):\n        super(CBOW, self).__init__()\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n        self.activation_function = nn.ReLU()\n        \n\n    def forward(self, inputs):\n        cbow = torch.mean(self.embeddings(inputs[0:4]),0).view(-1,1)\n        mat = self.embeddings(inputs[4:10])\n        dot_product = torch.matmul(mat,cbow)\n        return self.activation_function(dot_product)\n        \n\n\nmodel = CBOW(vocab_size, embedding_dims)\nmodel.to(device)\nloss_function = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n\n# setting target. Our target\ntarget = np.zeros(negative_sampling + 1)\ntarget[0] = 1.0\ntarget = torch.FloatTensor(target).view(-1,1).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:14:05.965962Z","iopub.execute_input":"2022-04-07T13:14:05.966217Z","iopub.status.idle":"2022-04-07T13:14:08.704105Z","shell.execute_reply.started":"2022-04-07T13:14:05.966181Z","shell.execute_reply":"2022-04-07T13:14:08.703239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_of_epochs = 10\nfor epoch in range(num_of_epochs):\n    total_loss = 0\n    for inp in tqdm(inp_contexts):\n        context_tensor = torch.tensor(inp, dtype=torch.long)\n        output = model(context_tensor.to(device))\n        total_loss += loss_function(output, target)\n        \n    #optimize at the end of each epoch\n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n    #Below TQDM log doesnt containg the time taken by back prop and optimizer","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:22:45.088328Z","iopub.execute_input":"2022-04-07T13:22:45.089144Z","iopub.status.idle":"2022-04-07T13:40:09.915894Z","shell.execute_reply.started":"2022-04-07T13:22:45.089108Z","shell.execute_reply":"2022-04-07T13:40:09.913954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ten = torch.tensor([index_dict['camera']])\nprint(model.embeddings(ten.to(device)))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:09.93651Z","iopub.execute_input":"2022-04-07T13:40:09.936736Z","iopub.status.idle":"2022-04-07T13:40:10.051899Z","shell.execute_reply.started":"2022-04-07T13:40:09.936709Z","shell.execute_reply":"2022-04-07T13:40:10.051135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving and Loading Model\ntorch.save(model, \"q2.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-04-07T12:46:58.047566Z","iopub.execute_input":"2022-04-07T12:46:58.047829Z","iopub.status.idle":"2022-04-07T12:46:58.064629Z","shell.execute_reply.started":"2022-04-07T12:46:58.0478Z","shell.execute_reply":"2022-04-07T12:46:58.063833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('cbow.pt')\nmodel.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedds = list(model.embeddings.parameters())[0].detach().cpu()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:10.07021Z","iopub.execute_input":"2022-04-07T13:40:10.070456Z","iopub.status.idle":"2022-04-07T13:40:10.153354Z","shell.execute_reply.started":"2022-04-07T13:40:10.070416Z","shell.execute_reply":"2022-04-07T13:40:10.152553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def top_10(word):\n    target_vec = embedds[index_dict[word]].numpy()\n\n    lst = []\n    for w in index_dict.keys():\n        lst.append([cosine_similarity([target_vec] , [embedds[index_dict[w]].numpy()]),w])\n\n    lst.sort(reverse=True)\n    # output 10 closest words\n    print('Top 10 closest word for the word {} are:'.format(word))\n    vecs = []\n    vals = []\n    close_words = []\n    for i in range(10):\n        vecs.append(embedds[index_dict[lst[i][1]]].numpy())\n        vals.append(lst[i][1])\n        close_words.append(lst[i][1])\n\n    print(close_words)\n        \n    pca = PCA(n_components = 2)\n    vecs = pca.fit_transform(vecs)\n    \n    plt.figure(figsize=(10,10))\n    plt.scatter(vecs[:,0], vecs[:,1])\n    for word, (x,y) in zip(vals, vecs):\n        plt.text(x, y, word)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:10.173284Z","iopub.execute_input":"2022-04-07T13:40:10.173501Z","iopub.status.idle":"2022-04-07T13:40:10.191332Z","shell.execute_reply.started":"2022-04-07T13:40:10.173476Z","shell.execute_reply":"2022-04-07T13:40:10.190142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_10('camera')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:10.192879Z","iopub.execute_input":"2022-04-07T13:40:10.193164Z","iopub.status.idle":"2022-04-07T13:40:10.233137Z","shell.execute_reply.started":"2022-04-07T13:40:10.193126Z","shell.execute_reply":"2022-04-07T13:40:10.232184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nouns\ntop_10('android')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:10.234062Z","iopub.status.idle":"2022-04-07T13:40:10.234875Z","shell.execute_reply.started":"2022-04-07T13:40:10.234595Z","shell.execute_reply":"2022-04-07T13:40:10.234624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# verb\ntop_10('play')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:10.236461Z","iopub.status.idle":"2022-04-07T13:40:10.23708Z","shell.execute_reply.started":"2022-04-07T13:40:10.236847Z","shell.execute_reply":"2022-04-07T13:40:10.236871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adjective\ntop_10('happy')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:10.238328Z","iopub.status.idle":"2022-04-07T13:40:10.239025Z","shell.execute_reply.started":"2022-04-07T13:40:10.238775Z","shell.execute_reply":"2022-04-07T13:40:10.238802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adjective\ntop_10('quick')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:40:10.240321Z","iopub.status.idle":"2022-04-07T13:40:10.241032Z","shell.execute_reply.started":"2022-04-07T13:40:10.240765Z","shell.execute_reply":"2022-04-07T13:40:10.240792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# verb\ntop_10('sad')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}