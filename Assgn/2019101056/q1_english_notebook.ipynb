{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/\n# perplexity values 4000 ke around aa rahi thi\nimport re\nimport random\nimport nltk\nimport math\nnltk.download('punkt')\nimport numpy as np\nimport pandas as pd\n# for progress bars\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"SDU58hz-RaiK","outputId":"c60dab1b-ee8c-4c5c-8947-534326aa6363","execution":{"iopub.status.busy":"2022-04-12T07:38:20.309017Z","iopub.execute_input":"2022-04-12T07:38:20.309758Z","iopub.status.idle":"2022-04-12T07:38:23.209760Z","shell.execute_reply.started":"2022-04-12T07:38:20.309659Z","shell.execute_reply":"2022-04-12T07:38:23.209054Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# HYPER PARAMETERS\n\n# sequence length for the sequence-target pair\nseq_len = 5\n\n# batch size\nbatch_size = 16\n\n# number of epochs\nepochs = 5\n\n# learning rate\nlr = 0.001\n\n# clip\nclip = 1\n\n# threshold -> for handling unknown words. If the frequency comes out to be less than threshold, then we will replace the token with unk\nthreshold = 2","metadata":{"id":"50zUTR4FRaiW","execution":{"iopub.status.busy":"2022-04-12T07:38:23.211337Z","iopub.execute_input":"2022-04-12T07:38:23.211583Z","iopub.status.idle":"2022-04-12T07:38:23.216882Z","shell.execute_reply.started":"2022-04-12T07:38:23.211552Z","shell.execute_reply":"2022-04-12T07:38:23.215930Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# read file\nfile_name = '../input/dataset/intro-to-nlp-assign3/europarl-corpus/train.europarl'\nf = open(file_name)\ntext = f.read()\nf.close()","metadata":{"id":"v0QW3wC-Raie","execution":{"iopub.status.busy":"2022-04-12T07:38:23.218104Z","iopub.execute_input":"2022-04-12T07:38:23.218404Z","iopub.status.idle":"2022-04-12T07:38:23.345227Z","shell.execute_reply.started":"2022-04-12T07:38:23.218369Z","shell.execute_reply":"2022-04-12T07:38:23.344582Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# data cleaning\ndef clean_data(text):\n    text = text.lower()\n    sentences = nltk.tokenize.sent_tokenize(text)\n\n    # keeping only alphabetical characters and apostrophe in our text\n    sentences = [re.sub(\"[^a-z' ]\", \" \", sent) for sent in sentences]\n    \n    # frequency count\n    freq = {}\n    for sent in sentences:\n        for word in sent.split():\n            if freq.get(word) == None:\n                freq[word] = 1\n            else:\n                freq[word] += 1\n                \n    pure_sentences = []\n    for sent in sentences:\n        pure = ''\n        for word in sent.split():\n            if freq[word] >= threshold:\n                pure += word\n            else:\n                pure += 'unk'\n                \n            pure += ' '\n        pure_sentences.append(pure)\n    \n    return pure_sentences\n\nsentences = clean_data(text)","metadata":{"id":"VR9UBvRYRaij","execution":{"iopub.status.busy":"2022-04-12T07:38:23.348897Z","iopub.execute_input":"2022-04-12T07:38:23.349491Z","iopub.status.idle":"2022-04-12T07:38:24.950465Z","shell.execute_reply.started":"2022-04-12T07:38:23.349445Z","shell.execute_reply":"2022-04-12T07:38:24.949754Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# creating sequence-target pair and also storing all the distinct words\nseq = []\ndist_words = set()\nfor string in sentences:\n    # we will take seq_len+1 and then divide this into input_sequence and output_sequence     \n    sent = string.split()\n    if len(sent) >= seq_len:\n        for i in range(seq_len,len(sent)):\n            seq.append(\" \".join(sent[i-seq_len:i+1]))\n        \n    for word in sent:\n        dist_words.add(word)\n        \n# vocabulary size\nvocab_size = len(dist_words)\n    \ninp = []\nout = []\nfor sq in seq:\n    inp.append(\" \".join(sq.split()[:-1]))  # from first word to last second word \n    out.append(\" \".join(sq.split()[1:]))   # from second word to last word\n\n    \n# creating word_to_index and index_to_word dictionary\nword_to_index = {}\nindex_to_word = {}\nfor cnt,word in enumerate(dist_words):\n    word_to_index[word] = cnt\n    index_to_word[cnt] = word","metadata":{"id":"n56ty9NBRaip","execution":{"iopub.status.busy":"2022-04-12T07:38:24.951817Z","iopub.execute_input":"2022-04-12T07:38:24.952069Z","iopub.status.idle":"2022-04-12T07:38:26.052830Z","shell.execute_reply.started":"2022-04-12T07:38:24.952035Z","shell.execute_reply":"2022-04-12T07:38:26.052077Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"joblib.dump(word_to_index,'word_to_index_q1.pkl')\njoblib.dump(index_to_word,'index_to_word_q1.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T07:38:26.055003Z","iopub.execute_input":"2022-04-12T07:38:26.055523Z","iopub.status.idle":"2022-04-12T07:38:26.273364Z","shell.execute_reply.started":"2022-04-12T07:38:26.055485Z","shell.execute_reply":"2022-04-12T07:38:26.272691Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['index_to_word_q1.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"print(vocab_size, len(inp))\nprint(seq[0]+'\\n'+inp[0]+'\\n'+out[0])","metadata":{"id":"DsHKSaKWRaiv","outputId":"659aca06-a6b3-4e26-8208-05547de34ae5","execution":{"iopub.status.busy":"2022-04-12T07:38:26.274610Z","iopub.execute_input":"2022-04-12T07:38:26.274992Z","iopub.status.idle":"2022-04-12T07:38:26.280196Z","shell.execute_reply.started":"2022-04-12T07:38:26.274949Z","shell.execute_reply":"2022-04-12T07:38:26.279463Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"9330 407107\nresumption of the session i declare\nresumption of the session i\nof the session i declare\n","output_type":"stream"}]},{"cell_type":"code","source":"# As we have got the index for each word, now convert inp and out to their corresponding word's indices\ninp_index = []\nout_index = []\nfor i in range(len(inp)):\n    inp_index.append([word_to_index[word] for word in inp[i].split()])\n    out_index.append([word_to_index[word] for word in out[i].split()])\n    \ninp_index = np.array(inp_index)\nout_index = np.array(out_index)","metadata":{"id":"lo7kcTW3Raiz","execution":{"iopub.status.busy":"2022-04-12T07:38:26.281391Z","iopub.execute_input":"2022-04-12T07:38:26.281771Z","iopub.status.idle":"2022-04-12T07:38:29.413682Z","shell.execute_reply.started":"2022-04-12T07:38:26.281733Z","shell.execute_reply":"2022-04-12T07:38:29.412934Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# creating batches\ndef make_batch(inp, out, batch_size):\n    ind = 0\n    for n in range(batch_size, len(inp), batch_size):\n        x = inp[ind:n,:]\n        y = out[ind:n,:]\n        ind = n\n        # yield is used to return from a function without destroying the states of its local variable \n        # and when the function is called, the execution starts from the last yield statement.         \n        yield x, y","metadata":{"id":"D-2ZS0LHRai2","execution":{"iopub.status.busy":"2022-04-12T07:38:29.414948Z","iopub.execute_input":"2022-04-12T07:38:29.415189Z","iopub.status.idle":"2022-04-12T07:38:29.422322Z","shell.execute_reply.started":"2022-04-12T07:38:29.415156Z","shell.execute_reply":"2022-04-12T07:38:29.421613Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Declaring out Model\nclass WordLSTM(nn.Module):\n    \n    def __init__(self, n_hidden=256, n_layers=4, drop_prob=0.3, lr=0.001):\n        super().__init__()\n\n        self.drop_prob = drop_prob\n        self.n_layers = n_layers\n        self.n_hidden = n_hidden\n        self.lr = lr\n        \n        self.emb_layer = nn.Embedding(vocab_size, 200)\n\n        ## define the LSTM\n        self.lstm = nn.LSTM(200, n_hidden, n_layers, \n                            dropout=drop_prob, batch_first=True)\n        \n        ## define a dropout layer\n        self.dropout = nn.Dropout(drop_prob)\n        \n        ## define the fully-connected layer\n        self.fc = nn.Linear(n_hidden, vocab_size)      \n    \n    def forward(self, x, hidden):\n        ''' Forward pass through the network. \n            These inputs are x, and the hidden/cell state `hidden`. '''\n\n        ## pass input through embedding layer\n        embedded = self.emb_layer(x)     \n        \n        ## Get the outputs and the new hidden state from the lstm\n        lstm_output, hidden = self.lstm(embedded, hidden)\n        \n        ## pass through a dropout layer\n        out = self.dropout(lstm_output)\n        \n        #out = out.contiguous().view(-1, self.n_hidden) \n        out = out.reshape(-1, self.n_hidden) \n\n        ## put \"out\" through the fully-connected layer\n        out = self.fc(out)\n\n        # return the final output and the hidden state\n        return out, hidden\n    \n    \n    def init_hidden(self, batch_size):\n        ''' initializes hidden state '''\n        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n        # initialized to zero, for hidden state and cell state of LSTM\n        weight = next(self.parameters()).data\n\n        # if GPU is available\n        if (torch.cuda.is_available()):\n            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n        \n        # if GPU is not available\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n        \n        return hidden","metadata":{"id":"jqo2eBaoRai6","execution":{"iopub.status.busy":"2022-04-12T07:38:29.425748Z","iopub.execute_input":"2022-04-12T07:38:29.426127Z","iopub.status.idle":"2022-04-12T07:38:29.438888Z","shell.execute_reply.started":"2022-04-12T07:38:29.426091Z","shell.execute_reply":"2022-04-12T07:38:29.438204Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# instantiate the model\nnet = WordLSTM()\n# push the model to GPU (avoid it if you are not using the GPU)\nnet.cuda()\nprint(net)","metadata":{"id":"EyBJhgEXRajA","outputId":"f03f7f5a-fe01-4102-f808-e4eb1f50553d","execution":{"iopub.status.busy":"2022-04-12T07:38:29.441560Z","iopub.execute_input":"2022-04-12T07:38:29.441739Z","iopub.status.idle":"2022-04-12T07:38:32.814823Z","shell.execute_reply.started":"2022-04-12T07:38:29.441710Z","shell.execute_reply":"2022-04-12T07:38:32.814062Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"WordLSTM(\n  (emb_layer): Embedding(9330, 200)\n  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=9330, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(net, epochs, batch_size, lr, clip):\n    opt = torch.optim.Adam(net.parameters(), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n    net.cuda()\n    \n    net.train()\n    for e in range(epochs):\n        # initialize hidden state\n        h = net.init_hidden(batch_size)\n        for x, y in make_batch(inp_index, out_index, batch_size):\n            inputs, targets = torch.from_numpy(x).cuda(), torch.from_numpy(y).cuda()\n            # detach hidden states\n            h = tuple([each.data for each in h])\n            net.zero_grad()\n            output, h = net(inputs, h)\n            loss = criterion(output, targets.view(-1))\n            loss.backward()\n            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n            nn.utils.clip_grad_norm_(net.parameters(), clip)\n            opt.step() \n        \n        print('Epoch {} done!'.format(e+1))","metadata":{"id":"neD0LytORajE","execution":{"iopub.status.busy":"2022-04-12T07:38:32.816309Z","iopub.execute_input":"2022-04-12T07:38:32.816545Z","iopub.status.idle":"2022-04-12T07:38:32.825558Z","shell.execute_reply.started":"2022-04-12T07:38:32.816510Z","shell.execute_reply":"2022-04-12T07:38:32.824747Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# train the model & save it\ntrain(net, epochs, batch_size, lr, clip)\ntorch.save(net.state_dict(),'q1_english.pt')","metadata":{"id":"a3STHj0fRajJ","execution":{"iopub.status.busy":"2022-04-12T07:38:32.827072Z","iopub.execute_input":"2022-04-12T07:38:32.827345Z","iopub.status.idle":"2022-04-12T07:51:11.382122Z","shell.execute_reply.started":"2022-04-12T07:38:32.827305Z","shell.execute_reply":"2022-04-12T07:51:11.381303Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1 done!\nEpoch 2 done!\nEpoch 3 done!\nEpoch 4 done!\nEpoch 5 done!\n","output_type":"stream"}]},{"cell_type":"code","source":"def perplexity(sentence):\n    # push to GPU\n    net.cuda()\n    net.eval()\n\n    # batch size is 1\n    h = net.init_hidden(1)\n    \n    sentence = sentence.lower()\n    sentence = re.sub(\"[^a-z']\", \" \", sentence)\n    indices = []\n    for token in sentence.split():\n        if word_to_index.get(token) == None:\n            indices.append(word_to_index['unk'])\n        else:\n            indices.append(word_to_index[token])\n\n    length = len(indices)\n    lst = np.array([indices])\n\n    # tensor inputs\n    inputs = torch.from_numpy(lst).cuda()\n\n    # get the output of the model\n    out, h = net(inputs, h)\n\n    # get the token probabilities\n    p = F.softmax(out, dim=1).data\n    p = p.cpu().numpy()\n\n    logarithm_sum = 0.0\n    for i,ind in enumerate(indices):\n        logarithm_sum += (math.log(p[i][ind]))/length\n        \n    # we already took division by length, so no need to divide here by length     \n    return math.exp(-logarithm_sum)\n    ","metadata":{"id":"HCeflk34RajM","execution":{"iopub.status.busy":"2022-04-12T07:51:11.383313Z","iopub.execute_input":"2022-04-12T07:51:11.385038Z","iopub.status.idle":"2022-04-12T07:51:11.393689Z","shell.execute_reply.started":"2022-04-12T07:51:11.384997Z","shell.execute_reply":"2022-04-12T07:51:11.392772Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"p = perplexity('the results are acceptable.')\nprint(p)","metadata":{"id":"SDj3_8a59Kls","execution":{"iopub.status.busy":"2022-04-12T07:51:11.394697Z","iopub.execute_input":"2022-04-12T07:51:11.395188Z","iopub.status.idle":"2022-04-12T07:51:11.417988Z","shell.execute_reply.started":"2022-04-12T07:51:11.395152Z","shell.execute_reply":"2022-04-12T07:51:11.417305Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"8988.339084997478\n","output_type":"stream"}]},{"cell_type":"code","source":"def calc_perplexity_and_write(output_path,dataset_path):\n    f = open(dataset_path)\n    text = f.read()\n    f.close()\n    \n    # text cleaning \n    text = text.lower()\n    sentences = nltk.tokenize.sent_tokenize(text)\n            \n    avg = 0.0\n    perplexity_score = []\n    N = len(sentences)\n    for sent in sentences:\n        try:\n            p = perplexity(sent)\n        except:\n            p = 1000.0\n        perplexity_score.append(p)\n        avg += p\n        \n    avg /= N\n    # thing to be written in the file     \n    to_write = ''\n    to_write += str(avg) + '\\n'\n    \n    for i,sent in enumerate(sentences):\n        to_write += sent\n        to_write += '     '\n        to_write += str(perplexity_score[i])\n        to_write += '\\n'\n        \n    file = open(output_path, 'w')\n    file.write(to_write)\n    file.close()","metadata":{"id":"HI1S8crqRajP","execution":{"iopub.status.busy":"2022-04-12T07:51:11.419369Z","iopub.execute_input":"2022-04-12T07:51:11.419656Z","iopub.status.idle":"2022-04-12T07:51:11.427551Z","shell.execute_reply.started":"2022-04-12T07:51:11.419615Z","shell.execute_reply":"2022-04-12T07:51:11.426690Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"calc_perplexity_and_write('2019101056_LM_train.txt','../input/dataset/intro-to-nlp-assign3/europarl-corpus/train.europarl')","metadata":{"id":"4t0GFh5lRajR","execution":{"iopub.status.busy":"2022-04-12T07:51:11.429219Z","iopub.execute_input":"2022-04-12T07:51:11.429400Z","iopub.status.idle":"2022-04-12T07:52:10.740973Z","shell.execute_reply.started":"2022-04-12T07:51:11.429372Z","shell.execute_reply":"2022-04-12T07:52:10.740260Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"calc_perplexity_and_write('2019101056_LM_test.txt','../input/dataset/intro-to-nlp-assign3/europarl-corpus/test.europarl')","metadata":{"id":"DKjCIHy7RajT","execution":{"iopub.status.busy":"2022-04-12T07:52:10.742285Z","iopub.execute_input":"2022-04-12T07:52:10.742533Z","iopub.status.idle":"2022-04-12T07:52:13.946545Z","shell.execute_reply.started":"2022-04-12T07:52:10.742501Z","shell.execute_reply":"2022-04-12T07:52:13.945818Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = torch.load('../input/new-models/q1_english.pt')\nnet.load_state_dict(model)\nnet.eval()\np = perplexity('the results are acceptable.')\nprint(p)","metadata":{"id":"BpddSgVhRajV","execution":{"iopub.status.busy":"2022-04-12T08:00:50.644667Z","iopub.execute_input":"2022-04-12T08:00:50.644946Z","iopub.status.idle":"2022-04-12T08:00:51.135795Z","shell.execute_reply.started":"2022-04-12T08:00:50.644916Z","shell.execute_reply":"2022-04-12T08:00:51.135111Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"8988.339084997478\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"L4rf-a8HRajY"},"execution_count":null,"outputs":[]}]}